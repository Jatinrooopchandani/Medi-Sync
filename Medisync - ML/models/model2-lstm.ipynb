{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.0698 - loss: 3.7692 - val_accuracy: 0.4474 - val_loss: 2.2695\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.4022 - loss: 2.2751 - val_accuracy: 0.6672 - val_loss: 1.4310\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.5743 - loss: 1.6184 - val_accuracy: 0.7092 - val_loss: 1.1410\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6307 - loss: 1.3770 - val_accuracy: 0.7295 - val_loss: 1.0070\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6883 - loss: 1.1631 - val_accuracy: 0.7469 - val_loss: 0.9307\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.7175 - loss: 1.0644 - val_accuracy: 0.7447 - val_loss: 0.8944\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7143 - loss: 1.0510 - val_accuracy: 0.7658 - val_loss: 0.8491\n",
      "Epoch 8/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7518 - loss: 0.9142 - val_accuracy: 0.7716 - val_loss: 0.8213\n",
      "Epoch 9/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7707 - loss: 0.8447 - val_accuracy: 0.7817 - val_loss: 0.7943\n",
      "Epoch 10/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.7726 - loss: 0.8329 - val_accuracy: 0.7854 - val_loss: 0.7734\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Accuracy:  0.77\n",
      "Precision:  0.75\n",
      "Recall:  0.75\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Hide Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Load the Dataset\n",
    "file_path = 'Hopsital Dataset.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "# 1. Convert 'Age' to numeric\n",
    "data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "data['Age'] = data['Age'].fillna(data['Age'].mean())\n",
    "\n",
    "# 2. Encode 'Gender'\n",
    "gender_mapping = {'Male': 0, 'Female': 1, 'Other': 2}\n",
    "data['Gender'] = data['Gender'].map(gender_mapping).fillna(2)\n",
    "\n",
    "# 3. Encode 'Name of Drug' (Target)\n",
    "drug_encoder = LabelEncoder()\n",
    "data['Name of Drug Encoded'] = drug_encoder.fit_transform(data['Name of Drug'])\n",
    "\n",
    "# 4. Tokenize and pad 'Diagnosis'\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data['Diagnosis'])\n",
    "data['Diagnosis Tokenized'] = tokenizer.texts_to_sequences(data['Diagnosis'])\n",
    "X_diagnosis = pad_sequences(data['Diagnosis Tokenized'], maxlen = 100)\n",
    "\n",
    "# 5. Combine Features\n",
    "X = np.hstack((X_diagnosis, data[['Age', 'Gender']].values))\n",
    "y = data['Name of Drug Encoded'].values\n",
    "\n",
    "# SMOTE\n",
    "unique, counts = np.unique(y, return_counts = True)\n",
    "drugs_with_multiple_instances = [x for x, cnt in zip(unique, counts) if cnt > 1]\n",
    "multiple_instances_filter = [x in drugs_with_multiple_instances for x in y]\n",
    "X = pd.DataFrame(X)[multiple_instances_filter].values\n",
    "y = pd.DataFrame(y)[multiple_instances_filter].values\n",
    "oversampler = SMOTE(k_neighbors = 1)\n",
    "X, y = oversampler.fit_resample(X, y)\n",
    "\n",
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim = 100, input_length=X_train.shape[1] - 2),  # Embedding for Diagnosis\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(drug_encoder.classes_), activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs = 10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred_lstm = model.predict(X_test)\n",
    "y_pred_lstm = [np.argmax(_) for _ in y_pred_lstm]\n",
    "\n",
    "lstm_report = classification_report(y_test, y_pred_lstm, output_dict = True)\n",
    "print(f\"Accuracy: {lstm_report[\"accuracy\"]: .2f}\")\n",
    "print(f\"Precision: {lstm_report[\"weighted avg\"][\"precision\"]: .2f}\")\n",
    "print(f\"Recall: {lstm_report[\"weighted avg\"][\"precision\"]: .2f}\")\n",
    "\n",
    "# Save the Model and Encoders\n",
    "model.save('lstm_drug_model.keras')\n",
    "with open('drug_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(drug_encoder, f)\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
